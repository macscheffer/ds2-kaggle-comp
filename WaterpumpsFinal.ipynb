{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import category_encoders as ce\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "pd.options.display.max_columns = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('Downloads/train_features.csv')\n",
    "test_features = pd.read_csv('Downloads/test_features.csv')\n",
    "train_labels = pd.read_csv('Downloads/train_labels.csv')\n",
    "test_labels = pd.read_csv('Downloads/SubmissionFormat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('Downloads/4910797b-ee55-40a7-8668-10efd5c1b960.csv')\n",
    "test_features = pd.read_csv('Downloads/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv')\n",
    "train_labels = pd.read_csv('Downloads/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv')\n",
    "test_labels = pd.read_csv('Downloads/SubmissionFormat.csv')\n",
    "df = train_features.append(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_recorded'] = pd.to_datetime(df.date_recorded).dt.month\n",
    "df['year_recorded'] = pd.to_datetime(df.date_recorded).dt.year\n",
    "df['dayofwk_recorded'] = pd.to_datetime(df.date_recorded).dt.weekday\n",
    "df['construction_year_missing'] = (df.construction_year == 0)\n",
    "df['constructYear_is_RecordYear'] = (df.year_recorded == df.construction_year)\n",
    "df['construction_year_from2014'] = 2014 - df.construction_year\n",
    "df.construction_year = df.construction_year.replace({0:1986})\n",
    "df['is_weekend?'] = ((df.dayofwk_recorded == 6) | (df.dayofwk_recorded == 0))\n",
    "df['construction_year_from_record'] = df.year_recorded - df.construction_year\n",
    "\n",
    "df['gps_height_zero'] = (df.gps_height == 0)\n",
    "df['gps_height_negative'] = (df.gps_height == 0)\n",
    "df['amount_tsh_zero'] = (df.amount_tsh == 0)\n",
    "\n",
    "df['source_marchine_dbh?'] = (df.source == 'machine dbh')\n",
    "df['scheme_name_missing?'] = (df.scheme_name != 'missing')\n",
    "df['ward_is_Igosi?'] = (df.ward == 'Igosi')\n",
    "\n",
    "df.public_meeting = df.public_meeting.fillna('missing')\n",
    "\n",
    "df['mgmt_is_wua?'] = (df.management == 'wua')\n",
    "df['is_parastatal'] = (df.management_group == 'parastatal')\n",
    "df['region_code_11?'] = (df.region_code == 11)\n",
    "df['region_code_2?'] = (df.region_code == 2)\n",
    "\n",
    "df['my_source_classes'] = df.source_type.map(\n",
    "    {\n",
    "    'spring': 'good', 'shallow well': 'ok',\n",
    "    'borehole':'ok', 'river/lake':'good',\n",
    "    'rainwater harvesting': 'good', 'dam': 'bad',\n",
    "    'other': 'ok'})\n",
    "\n",
    "df.funder = df.funder.fillna('missing')\n",
    "df.installer = df.installer.fillna('missing')\n",
    "df.public_meeting = df.public_meeting.fillna('missing')\n",
    "\n",
    "\n",
    "df['yearMo_reacorded_fractional'] = df.year_recorded + (df.month_recorded -1)/ 12\n",
    "df['year_recorded_from_2014'] = 2014 -- df.yearMo_reacorded_fractional\n",
    "\n",
    "df.installer = df.installer.astype(str)\n",
    "\n",
    "df.funder = df.funder.str.lower()\n",
    "df.installer = df.installer.str.lower()\n",
    "df['funder_is_installer'] = (df.funder == df.installer)\n",
    "\n",
    "\n",
    "df['population_over_215'] = (df.population >= 215)\n",
    "\n",
    "df.installer.astype(str)\n",
    "\n",
    "df['funder_is_gov'] = df.funder.str.contains('gov')\n",
    "df['installer_is_gov'] = df.installer.str.contains('gov')\n",
    "df['funder_is_wor'] = df.funder.str.contains('wor')\n",
    "df['more_than_one_basin'] = (df.basin.str.contains('/'))\n",
    "df['more_than_one_funder'] = df.funder.str.contains('/')\n",
    "df['space_in_funder_name'] = df.funder.str.contains(' ')\n",
    "df['space_in_installer_name'] = df.installer.str.contains(' ')\n",
    "\n",
    "df.lga = df.lga.str.lower()\n",
    "df.ward = df.ward.str.lower()\n",
    "\n",
    "df['payment_unknown_doesnt_pay'] = ((df.payment == 'unknown') | (df.payment == 'never pay'))\n",
    "\n",
    "df.scheme_name = df.scheme_name.str.lower()\n",
    "df['scheme_name_len_1'] = (df.scheme_name.str.len() == 1)\n",
    "df['scheme_name_con_gov'] = (df.scheme_name.str.contains('gov'))\n",
    "df['scheme_name_con_supply'] = (df.scheme_name.str.contains('supply'))\n",
    "df['scheme_name_con_space'] = (df.scheme_name.str.contains(' '))\n",
    "\n",
    "df.scheme_management = df.scheme_management.str.lower()\n",
    "df['scheme_mgmt_contains_w'] = (df.scheme_management.str.contains('w'))\n",
    "df['scheme_mgmt_contains_p'] = (df.scheme_management.str.contains('p'))\n",
    "df['scheme_mgmt_is_not_known'] = (df.scheme_management.str.contains('other') | df.scheme_management.str.contains('none') | df.scheme_management.str.contains('missing'))\n",
    "\n",
    "df['num_private_over0'] = (df.num_private > 0)\n",
    "df['num_private_over1'] = (df.num_private > 1)\n",
    "df['num_private_over10'] = (df.num_private > 10)\n",
    "df['num_private_over100'] = (df.num_private > 100)\n",
    "\n",
    "# june, july, august, september, october is tanzania dry season\n",
    "df['quantity_is_seasonal'] = (df.quantity == 'seasonal')\n",
    "df['dry_season'] = ((df.month_recorded >= 6) & (df.month_recorded <= 10))\n",
    "df['wet_season'] = ((df.month_recorded == 12) | (df.month_recorded <= 4))\n",
    "\n",
    "df['day_of_year'] = pd.to_datetime(df.date_recorded).dt.dayofyear\n",
    "df['days_away_from_middle_of_year'] = 180 - df.day_of_year\n",
    "\n",
    "df.wpt_name = df.wpt_name.str.lower()\n",
    "df['wpt_name_none'] = (df.wpt_name == 'none')\n",
    "\n",
    "df.region_code = df.region_code.astype(str)\n",
    "df.district_code = df.district_code.astype(str)\n",
    "\n",
    "df['gps_height_squared'] = df.gps_height ** 2\n",
    "df['amount_tsh_squared'] = df.amount_tsh ** 2\n",
    "df['days_away_from_middle_of_year_squared'] = df.days_away_from_middle_of_year ** 2\n",
    "df['dayofwk_recorded_str'] = df.dayofwk_recorded.astype(str)\n",
    "df['construction_year_from2014_squared'] = df.construction_year_from2014 ** 2\n",
    "\n",
    "df['source_discrep'] = (df.source != df.source_type)\n",
    "df['quality_discrep'] = (df.water_quality != df.quality_group)\n",
    "\n",
    "df['extraction_type_includes_other'] = df.extraction_type.str.contains('other')\n",
    "df['extraction_type_gravity'] = (df.extraction_type_class == 'gravity')\n",
    "\n",
    "\n",
    "installer_names = list(df.installer.value_counts().index)\n",
    "installer_instances = list(df.installer.value_counts().values)\n",
    "\n",
    "installer_map = {}\n",
    "\n",
    "for installer, instances in zip(installer_names, installer_instances):\n",
    "    installer_map[installer] = instances\n",
    "\n",
    "\n",
    "funder_names = list(df.funder.value_counts().index)\n",
    "funder_instances = list(df.installer.value_counts().values)\n",
    "\n",
    "funder_map = {}\n",
    "\n",
    "for funder, instances in zip(funder_names, funder_instances):\n",
    "    funder_map[funder] = instances\n",
    "    \n",
    "df['installer_experience'] = df.installer.map(installer_map)\n",
    "df['funder_experience'] = df.funder.map(funder_map)\n",
    "\n",
    "\n",
    "\n",
    "installer_names2 = list(df.groupby('installer').construction_year.min().index)\n",
    "installer_min_year = list(df.groupby('installer').construction_year.min().values)\n",
    "\n",
    "installer_map2 = {}\n",
    "\n",
    "for installer, yr in zip(installer_names2, installer_min_year):\n",
    "    installer_map2[installer] = yr\n",
    "    \n",
    "\n",
    "df['installer_first_construct_year'] = df.installer.map(installer_map2)\n",
    "\n",
    "installer_names3 = list(df.groupby('installer').construction_year.max().index)\n",
    "installer_max_year = list(df.groupby('installer').construction_year.max().values)\n",
    "\n",
    "installer_map3 = {}\n",
    "\n",
    "for installer, yr in zip(installer_names3, installer_max_year):\n",
    "    installer_map3[installer] = yr\n",
    "    \n",
    "\n",
    "df['installer_last_construct_year'] = df.installer.map(installer_map3)\n",
    "\n",
    "\n",
    "installer_names4 = list(df.groupby('installer').construction_year.mean().index)\n",
    "installer_mean_year = list(df.groupby('installer').construction_year.mean().values)\n",
    "\n",
    "installer_map4 = {}\n",
    "\n",
    "for installer, yr in zip(installer_names4, installer_mean_year):\n",
    "    installer_map4[installer] = yr\n",
    "    \n",
    "\n",
    "df['installer_mean_construction_year'] = df.installer.map(installer_map4)\n",
    "\n",
    "df['installer_funder_exp'] = df.installer_experience + df.funder_experience\n",
    "df['record_year_from_2014'] = 2014 - df.year_recorded\n",
    "\n",
    "loc_features = ['gps_height', 'longitude', 'latitude']\n",
    "\n",
    "std_sc = StandardScaler()\n",
    "df_std = std_sc.fit_transform(df[loc_features])\n",
    "pca_all = PCA(3)\n",
    "pc_all = pca_all.fit_transform(X=df_std)\n",
    "\n",
    "pca3_df = pd.DataFrame({'pc1':pc_all[:,0],'pc2':pc_all[:,1], 'pc3': pc_all[:, 2]})\n",
    "\n",
    "\n",
    "kms = [2, 5, 15]\n",
    "\n",
    "for means in kms:\n",
    "    km = KMeans(n_clusters=means)\n",
    "    km = km.fit(pca3_df[['pc1', 'pc2', 'pc3']])\n",
    "    df['XYZ_Cluster_Label_' + str(means)] = km.labels_\n",
    "\n",
    "df['installer_longevity'] = df.installer_last_construct_year - df.installer_first_construct_year\n",
    "df['installer_installations_per_year'] = df.installer_experience / df.installer_longevity\n",
    "\n",
    "for name in list(df.wpt_name.value_counts()[1:15].index):\n",
    "    df['wpt_name_' + name] = (df.wpt_name == name)\n",
    "\n",
    "df.subvillage = df.subvillage.str.lower()\n",
    "for village in list(df.subvillage.value_counts()[:10].index):\n",
    "    df['subvillage_' + village] = (df.subvillage == village)\n",
    "    \n",
    "for lg in list(df.lga.value_counts()[:19].index):\n",
    "    df['lga_' + lg] = (df.lga == lg)\n",
    "    \n",
    "for wrd in list(df.ward.value_counts()[:13].index):\n",
    "    df['ward_' + wrd] = (df.ward == wrd)\n",
    "    \n",
    "for fndr in list(df.funder.value_counts()[:12].index):\n",
    "    df['funder_' + fndr] = (df.funder == fndr)\n",
    "    \n",
    "for inst in list(df.installer.value_counts()[:9].index):\n",
    "    df['installer_' + inst] = (df.installer == inst)\n",
    "    \n",
    "df['lga_ward_same'] = (df.lga == df.ward)\n",
    "\n",
    "df = df.fillna('missing')\n",
    "\n",
    "for ins in list(df.installer.value_counts()[:9].index):\n",
    "    df['installer_' + ins] == (df.installer == ins)\n",
    "\n",
    "df.payment_type = pd.factorize(df.payment_type)[0]\n",
    "df.water_quality = pd.factorize(df.water_quality)[0]\n",
    "df.scheme_management = pd.factorize(df.scheme_management)[0]\n",
    "df.extraction_type = pd.factorize(df.extraction_type)[0]\n",
    "df.funder = pd.factorize(df.funder)[0]\n",
    "df.waterpoint_type = pd.factorize(df.waterpoint_type)[0]\n",
    "df.lga = pd.factorize(df.lga)[0]\n",
    "df.source = pd.factorize(df.source)[0]\n",
    "df.quantity = pd.factorize(df.quantity)[0]\n",
    "df.basin = pd.factorize(df.basin)[0]\n",
    "df.management = pd.factorize(df.management)[0]\n",
    "df.region = pd.factorize(df.region)[0]\n",
    "df.district_code = pd.factorize(df.district_code)[0]\n",
    "df.my_source_classes = pd.factorize(df.my_source_classes)[0]\n",
    "df.installer = pd.factorize(df.installer)[0]\n",
    "\n",
    "\n",
    "df['amount_tsh_not0_over500'] = ((df.amount_tsh != 0) & (df.amount_tsh >= 500))\n",
    "df['amount_tsh_not0_over1000'] = ((df.amount_tsh != 0) & (df.amount_tsh >= 1000))\n",
    "df['amount_tsh_not0_over5000'] = ((df.amount_tsh != 0) & (df.amount_tsh >= 10000))\n",
    "df['amount_tsh_not0_over10000'] = ((df.amount_tsh != 0) & (df.amount_tsh >= 10000))\n",
    "\n",
    "df['population_over1'] = (df.population >= 2)\n",
    "df['population_under50'] = (df.population < 50)\n",
    "\n",
    "df['gps_height_pct'] = df.gps_height / 2777\n",
    "\n",
    "df['region_district_combo'] = df.region.astype(str) + df.district_code.astype(str)\n",
    "df['water_region_district_combo'] = df.waterpoint_type.astype(str) + df.region_district_combo\n",
    "df['water_region_district_factorized'] = pd.factorize(df.water_region_district_combo)[0]\n",
    "df['region_district_combo_factorized'] = pd.factorize(df.region_district_combo)[0]\n",
    "\n",
    "df['basin_region_district_combo'] = df.region_district_combo + df.basin.astype(str)\n",
    "df['basin_region_district_factorized'] = pd.factorize(df.basin_region_district_combo)[0]\n",
    "\n",
    "df['management_group_factorized'] = pd.factorize(df.management_group)[0]\n",
    "df['mgmt_mgmt_group_combined'] = df.management.astype(str) + df.management_group_factorized.astype(str)\n",
    "df['mgmt_mgmt_group_combined'] = pd.factorize(df.mgmt_mgmt_group_combined)[0]\n",
    "\n",
    "def mac_wpt_name_mapper(wpt_name):\n",
    "    \n",
    "    # 75 wpt names\n",
    "    \n",
    "    wpt_names = ['none', 'shuleni', 'zahanati', 'msikitini', 'kanisani', 'sokoni',\n",
    "       'bombani', 'ofisini', 'school', 'shule ya msingi', 'shule', 'sekondari',\n",
    "       'muungano', 'mkombozi', 'upendo', 'madukani', 'mbugani',\n",
    "       'kituo cha afya', 'umoja', 'mkuyuni', 'hospital', 'center', 'kisimani',\n",
    "       'ccm', 'mtakuja', 'ofisi ya kijiji', 'songambele', 'bwawani', 'tankini',\n",
    "       'bondeni', 'maendeleo', 'kilabuni', 'mbuyuni', 'uwanjani', 'kijiweni',\n",
    "       'shuleni sekondari', 'miembeni', 'mnadani', 'secondary', 'rc church',\n",
    "       'mwembeni', 'amani', 'majengo', 'dispensary', 'mahakamani', 'mashineni',\n",
    "       'tank la shule', 'church', 'tenkini', 'mtoni', 'darajani', 'barabarani',\n",
    "       'kwa juma', 'kwa john', 'tumaini', 'polisi', 'tupendane', 'mkwajuni',\n",
    "       'tangini', 'kwa joseph', 'mission', 'kwa charles', 'ushirika',\n",
    "       'magereza', 'kwa', 'jamii', 'mshikamano', 'mlimani', 'joshoni',\n",
    "       'stendi', 'juhudi', 'kwa samweli', 'ofisi ya kata', 'kolongoni',\n",
    "       'machinjioni']\n",
    "    \n",
    "    if wpt_name in wpt_names:\n",
    "        return wpt_name\n",
    "    \n",
    "    return 'misc'\n",
    "\n",
    "df['mac_wpt_name'] = df.wpt_name.apply(mac_wpt_name_mapper)\n",
    "df['mac_wpt_name'] = pd.factorize(df.mac_wpt_name)[0]\n",
    "\n",
    "\n",
    "def mac_installer_mapper(installer):\n",
    "    \n",
    "    # 75 installer names\n",
    "    \n",
    "    installers =  [5,  19,  28,  35,  31,  23,   9,  16,  30,  60,  21,  79,   2,\n",
    "             12,  48,  37, 142,  73,  58,  25,  11,  62,  78,  93,  43,  92,\n",
    "             18,  36,  33, 162, 186,   3,  34,  97,  66,  87, 232,  95,  39,\n",
    "            130,  80,  67, 205,   6,  10, 132, 197, 195,  85,  27, 156,  69,\n",
    "              8, 165,  91, 179,  84, 160, 115, 123,   7, 143,  90,  81,  14,\n",
    "              4,  44,  59, 135, 121,  40, 149,  70,  13,  26, 145, 184, 146,\n",
    "            173, 246,  64, 181,  71, 223, 252,   0,  22, 227, 300,  54,  46,\n",
    "            321, 347, 139, 169, 102, 236, 310, 141, 137]\n",
    "    if installer in installers:\n",
    "        return installer\n",
    "    \n",
    "    return 'misc'\n",
    "df['mac_installer'] = df.installer.apply(mac_installer_mapper)\n",
    "df['mac_installer'] = pd.factorize(df.mac_installer)[0]\n",
    "\n",
    "def mac_funder_mapper(funder):\n",
    "    \n",
    "    # 20 funder names\n",
    "    \n",
    "    funders = [20,  25,  11,  16,   7,  68,  39,  12,   3,  63,  81,  32,  23,\n",
    "              6,  70,  41,  58,  22,  56,  89,  45,  59, 132,  90,  31,  88,\n",
    "             73, 114,  46,   8,  15,  18,  10, 165, 202,  98,   0,  42,  29,\n",
    "             53, 142,  72, 210, 112, 226, 251, 180, 128,  13, 152,  75, 163,\n",
    "            129, 117, 101,  37,  35,  80,  62,  83, 130,   5,  64, 149, 189,\n",
    "            102, 100, 170,  49, 159, 213, 123,  51,  82,  84, 262, 135, 138,\n",
    "             40, 107, 245, 109, 253, 146,  33, 167,  97, 166,  94,  76,  69,\n",
    "            240,  17, 252,  55,  50, 343,  24, 282, 162]\n",
    "    \n",
    "    if funder in funders:\n",
    "        return funder\n",
    "    \n",
    "    return 'misc'\n",
    "\n",
    "df['mac_funder'] = df.funder.apply(mac_funder_mapper)\n",
    "df['mac_funder'] = pd.factorize(df.mac_funder)[0]\n",
    "\n",
    "def mac_subvillage_mapper(subvillage):\n",
    "    \n",
    "    # 100 subvillage names\n",
    "    \n",
    "    subvillages = ['shuleni', 'majengo', 'madukani', 'missing', 'kati', 'mtakuja',\n",
    "       'sokoni', 'm', 'muungano', 'mbuyuni', 'songambele', 'mlimani',\n",
    "       'miembeni', 'msikitini', '1', 'kanisani', 'kibaoni', 'mjini',\n",
    "       'mjimwema', 'mapinduzi', 'mwenge', 'mkwajuni', 'i', 'bondeni', 'azimio',\n",
    "       'mabatini', 'amani', 'mbugani', 'mission', 'kichangani',\n",
    "       'mtaa wa kitunda kati', 'changombe', 'senta', 'bwawani', 'zahanati',\n",
    "       'nyerere', 'misufini', 'kisiwani', 'center', 'k', 'kawawa', 'maendeleo',\n",
    "       'mtaa wa kivule', 'ccm', 'ikulu', 'ushirika', 'barabarani', 'gulioni',\n",
    "       'shule', 'msufini', 'ilala', 'magharibi', 'msumbiji', 'darajani',\n",
    "       'marurani juu', 'uzunguni', 'marurani kati', 'dodoma', 'misheni',\n",
    "       'mpakani', 'zaire', 'ofisini', 'elimu', 'sokoine', 'kilimahewa',\n",
    "       'bomani', 'magomeni', 'kaloleni', 'ngelele', 'minazini', 'mkuyuni',\n",
    "       'mnadani', 'ujamaa', 'katumba', 'vikuge', 'muongozo', 'mnazi mmoja',\n",
    "       'usalama', 'mashariki', 'mikoroshini', 'migombani', 'mwangaza',\n",
    "       'kijijini', 'mwabasabi', 'bombani', 'kiwanjani', 'mnazimmoja',\n",
    "       'chemchem', 'mchangani', 'uswahilini', 'mtaa wa vikongoro', 'mtoni',\n",
    "       'l', 'njiapanda', 'stendi', 'gezaulole', 'isanga', 'njia panda',\n",
    "       'kakola', 'tandika']\n",
    "    \n",
    "    if village in subvillages:\n",
    "        return village\n",
    "    \n",
    "    return 'misc'\n",
    "\n",
    "df['mac_subvillage'] = df.subvillage.apply(mac_subvillage_mapper)\n",
    "df['mac_subvillage'] = pd.factorize(df.mac_subvillage)[0]\n",
    "\n",
    "def mac_ward_mapper(ward):\n",
    "    \n",
    "    # 100 ward names\n",
    "    \n",
    "    wards = ['igosi', 'imalinyi', 'siha kati', 'mdandu', 'nduruma', 'kitunda',\n",
    "       'mishamo', 'msindo', 'chalinze', 'maji ya chai', 'usuka',\n",
    "       'ngarenanyuki', 'chanika', 'vikindu', 'mtwango', 'zinga/ikerege',\n",
    "       'matola', 'magomeni', 'maramba', 'mvomero', 'wangingombe', 'ifakara',\n",
    "       'itete', 'olkokola', 'kikatiti', 'nkoma', 'maposeni', 'mahongole',\n",
    "       'rujewa', 'igongolo', 'masama magharibi', 'mlangali', 'hedaru',\n",
    "       'kidatu', 'simbo', 'ihanda', 'lupalilo', 'kagongo', 'kiranyi',\n",
    "       'nkungulu', 'isongole', 'yombo', 'chinamili', 'makwale', 'kanga',\n",
    "       'diongoya', 'soga', 'kimochi', 'siha mashariki', 'masama mashariki',\n",
    "       'tinde', 'ilolangulu', 'malindi', 'makuyuni', 'bugarama',\n",
    "       'mabwerebwere', 'mkongo', 'kibaoni', 'mangula', 'ruanda', 'muzye',\n",
    "       'wino', 'lembeni', 'mhunze', 'kenyamonta', 'mahembe',\n",
    "       'kirua vunjo kusini', 'mamire', 'kakonko', 'rusumo', 'mkula',\n",
    "       'chanzuru', 'mlali', 'leguruki', 'ubaruku', 'murufiti', 'bungu',\n",
    "       'kisesa', 'kibosho magharibi', 'magagura', 'matendo', 'lumemo',\n",
    "       'kifanya', 'chimala', 'mlangarini', 'uwemba', 'mpuguso', 'ruhembe',\n",
    "       'munyegera', 'ipande', 'rungwe mpya', 'muhinda', 'igurusi',\n",
    "       'mbulumbulu', 'ilkidinga', 'msia', 'lupembe', 'busole', 'bumera',\n",
    "       'kidodi']\n",
    "    if ward in wards:\n",
    "        return ward\n",
    "    \n",
    "    return 'misc'\n",
    "\n",
    "df['mac_wards'] = df.ward.apply(mac_ward_mapper)\n",
    "df['mac_wards'] = pd.factorize(df.mac_wards)[0]\n",
    "\n",
    "\n",
    "df['cartesian_lat'] = np.cos(df.latitude) * np.cos(df.longitude) * df.gps_height\n",
    "df['cartesian_long'] = np.cos(df.latitude) * np.sin(df.longitude) * df.gps_height\n",
    "df['cartesian_altitude'] = np.sin(df.latitude) * df.gps_height\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['construction_year_over2002'] = (df.construction_year > 2002) # openly said they wanna be better\n",
    "df['construction_year_over2006'] = (df.construction_year > 2006) # legislation\n",
    "df['construction_year_over2009'] = (df.construction_year > 2009) # new reporting standards\n",
    "\n",
    "df['basin_is_3'] = (df.basin == 3)\n",
    "\n",
    "\n",
    "df['mac_population_encoded'] = df.population.map({1:1, 0:2}).fillna(3)\n",
    "df['wpt_name_school'] =((df.wpt_name.str.contains('shul')) | (df.wpt_name.str.contains('school')))\n",
    "df['wpt_name_kwa'] =((df.wpt_name.str.contains('kwa')))\n",
    "df['wpt_name_church'] = ((df.wpt_name.str.contains('msikitini')) | (df.wpt_name.str.contains('kanisani')) | (df.wpt_name.str.contains('kwa')))\n",
    "df['wpt_name_charles'] = (df.wpt_name.str.contains('charles'))\n",
    "df['wpt_name_market'] = ((df.wpt_name.str.contains('soko')) | (df.wpt_name.str.contains('madukani')))\n",
    "df['wpt_name_hospital'] = ((df.wpt_name.str.contains('kituo')) | (df.wpt_name.str.contains('afya')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371000):\n",
    "    \"\"\"\n",
    "    Vectorized great circle distance between two points\n",
    "    (lat, lon) specified in decimal degrees or in radians)\n",
    "    Returns units in meters\n",
    "    \"\"\"\n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return earth_radius * 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "\n",
    "def append_dist_to_group_center(df, group_col='basin'):\n",
    "    lats = {}\n",
    "    lons = {}\n",
    "\n",
    "    grouped = df.groupby(group_col)\n",
    "    for group_name, group_df in grouped:\n",
    "        points = list(zip(group_df.latitude, group_df.longitude))\n",
    "\n",
    "        hull = ConvexHull(points)\n",
    "        form = [points[i] for i in hull.vertices]\n",
    "\n",
    "        lats[group_name] = np.mean(hull.points[hull.vertices,0])\n",
    "        lons[group_name] = np.mean(hull.points[hull.vertices,1])\n",
    "\n",
    "    centroids_df = (pd.DataFrame([lats, lons]).T\n",
    "                      .rename(columns={0:f'{group_col}_lat', 1:f'{group_col}_lon'}))\n",
    "\n",
    "    df = df.merge(centroids_df, left_on=group_col, right_index=True)\n",
    "\n",
    "    df[f'dist_to_{group_col}'] = haversine(df.latitude, df.longitude,\n",
    "                                           df[f'{group_col}_lat'], df[f'{group_col}_lon'])\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = append_dist_to_group_center(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train_labels, df, on='id', how='inner')\n",
    "train['functional'] = (train.status_group == 'functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macs_labelEncode_meaningful(df, train, cols, target):\n",
    "    \n",
    "    for col in cols:\n",
    "        \n",
    "        cur_encodes = pd.factorize(train.pivot_table(index=col, values=target).sort_values(target).index)[1].tolist()\n",
    "        fnl_encodes = pd.factorize(train.pivot_table(index=col, values=target).sort_values(target).index)[0].tolist()\n",
    "        \n",
    "        mapper_dic = dict(zip(cur_encodes, fnl_encodes))\n",
    "        \n",
    "        df['MeaningfulEnc_' + col] = df[col].map(mapper_dic)\n",
    "        \n",
    "    return df\n",
    "\n",
    "make_me_meaningful = ['basin', 'region', 'lga', 'payment_type',\n",
    "                      'quantity', 'source', 'waterpoint_type',\n",
    "                      'district_code', 'mac_installer', 'mac_funder',\n",
    "                      'scheme_management', 'XYZ_Cluster_Label_15']\n",
    "\n",
    "\n",
    "df = macs_labelEncode_meaningful(df, train, make_me_meaningful, 'functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_labels, df, on='id', how='inner')\n",
    "test = pd.merge(test_labels, df, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mac_population_encoded'] = df.population.map({1:1, 0:2}).fillna(3)\n",
    "df['wpt_name_school'] =((df.wpt_name.str.contains('shul')) | (df.wpt_name.str.contains('school')))\n",
    "df['wpt_name_kwa'] =((df.wpt_name.str.contains('kwa')))\n",
    "df['wpt_name_church'] = ((df.wpt_name.str.contains('msikitini')) | (df.wpt_name.str.contains('kanisani')) | (df.wpt_name.str.contains('kwa')))\n",
    "df['wpt_name_charles'] = (df.wpt_name.str.contains('charles'))\n",
    "\n",
    "\n",
    "train['mac_population_encoded'] = train.population.map({1:1, 0:2}).fillna(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['functional'] = (train.status_group == 'functional')\n",
    "df['wpt_name_charles'] = (df.wpt_name.str.contains('charles'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23423, 239)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.wpt_name_kwa].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3.0\n",
       "11       3.0\n",
       "19       1.0\n",
       "20       3.0\n",
       "33       3.0\n",
       "36       2.0\n",
       "41       2.0\n",
       "47       2.0\n",
       "52       2.0\n",
       "80       2.0\n",
       "109      2.0\n",
       "113      2.0\n",
       "120      2.0\n",
       "124      2.0\n",
       "135      3.0\n",
       "140      2.0\n",
       "211      2.0\n",
       "213      2.0\n",
       "215      2.0\n",
       "254      2.0\n",
       "270      2.0\n",
       "275      3.0\n",
       "303      2.0\n",
       "307      2.0\n",
       "312      2.0\n",
       "328      3.0\n",
       "332      2.0\n",
       "348      3.0\n",
       "362      2.0\n",
       "373      3.0\n",
       "        ... \n",
       "13676    2.0\n",
       "13709    2.0\n",
       "13723    3.0\n",
       "13770    2.0\n",
       "13818    2.0\n",
       "13845    2.0\n",
       "13847    2.0\n",
       "13887    3.0\n",
       "13893    1.0\n",
       "13908    3.0\n",
       "14026    3.0\n",
       "14043    2.0\n",
       "14058    1.0\n",
       "14085    2.0\n",
       "14089    3.0\n",
       "14125    2.0\n",
       "14169    2.0\n",
       "14174    3.0\n",
       "14182    2.0\n",
       "14216    1.0\n",
       "14231    3.0\n",
       "14257    2.0\n",
       "14260    2.0\n",
       "14270    3.0\n",
       "14290    2.0\n",
       "14291    2.0\n",
       "14294    3.0\n",
       "14295    1.0\n",
       "14296    3.0\n",
       "14301    2.0\n",
       "Name: mac_population_encoded, Length: 73758, dtype: float64"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mac_population_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_wards'] = ((df.ward == 'igosi') | (df.ward == 'imalinyi') | (df.ward == 'siha kati'))\n",
    "df['second_best_wards'] = ((df.ward == 'mdandu') | (df.ward == 'nduruma'))\n",
    "df.public_meeting = pd.factorize(df.public_meeting)[0]\n",
    "\n",
    "train['best_wards'] = ((train.ward == 'igosi') | (train.ward == 'imalinyi') | (train.ward == 'siha kati'))\n",
    "train['second_best_wards'] = ((train.ward == 'mdandu') | (train.ward == 'nduruma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.public_meeting = pd.factorize(df.public_meeting)[0]\n",
    "train = pd.merge(train_labels, df, on='id', how='inner')\n",
    "test = pd.merge(test_labels, df, on='id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = ['latitude', 'longitude', 'gps_height',\n",
    "                'mac_funder', 'mac_installer', 'scheme_management', 'extraction_type', 'management', \n",
    "                'payment_type', 'water_quality', 'quantity', 'source', 'waterpoint_type',\n",
    "                'basin', 'region', 'lga', 'district_code', 'population', 'amount_tsh',\n",
    "                'construction_year_from_record', 'day_of_year', 'funder_is_gov', 'my_source_classes',\n",
    "                'best_wards', 'installer_experience', 'mac_population_encoded', 'funder_experience', \n",
    "                'second_best_wards', 'num_private_over100', 'public_meeting', 'mac_wards', 'amount_tsh_not0_over1000' ]\n",
    "\n",
    "len(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mac\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mac\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   43.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8134343434343434, total=  39.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mac\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mac\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8134848484848485, total=  35.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-714-89eb9799ba05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    711\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1110\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = train[new_features]\n",
    "y = train.status_group\n",
    "\n",
    "#pipe = make_pipeline(RobustScaler(), XGBClassifier(n_estimators=80, objective = 'multi:softprob', booster = 'gbtree', nrounds = 'min.error.idx', \n",
    "#                    num_class = 4, maximize = False, eval_metric = 'merror', eta = .3,\n",
    "#                     max_depth = 16, colsample_bytree = 1, reg_lambda=5))\n",
    "\n",
    "pipe = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx', tree_method='exact',\n",
    "                      num_class = 4, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 14, colsample_bytree=.35)\n",
    "\n",
    "\n",
    "scores = cross_validate(pipe, X, y, scoring='accuracy', cv=3,verbose=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103367003367002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([30.82181549, 35.66789603, 30.86454654]),\n",
       " 'score_time': array([1.83010626, 1.83110118, 1.88592386]),\n",
       " 'test_score': array([0.81075758, 0.81136364, 0.80888889]),\n",
       " 'train_score': array([0.93406566, 0.93487374, 0.93659091])}"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scores['test_score'].mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude 0.012750058\n",
      "longitude 0.011068806\n",
      "gps_height 0.011133743\n",
      "mac_funder 0.013615662\n",
      "mac_installer 0.013209927\n",
      "scheme_management 0.01716719\n",
      "extraction_type 0.048680663\n",
      "management 0.015412217\n",
      "payment_type 0.02960061\n",
      "water_quality 0.021627367\n",
      "quantity 0.27013025\n",
      "source 0.022972358\n",
      "waterpoint_type 0.090314835\n",
      "basin 0.018141368\n",
      "region 0.017756391\n",
      "lga 0.02238242\n",
      "district_code 0.017273735\n",
      "population 0.012270914\n",
      "amount_tsh 0.02065708\n",
      "construction_year_from_record 0.016191898\n",
      "day_of_year 0.012359123\n",
      "funder_is_gov 0.023413325\n",
      "my_source_classes 0.036156904\n",
      "best_wards 0.021932336\n",
      "installer_experience 0.01551933\n",
      "mac_population_encoded 0.017334022\n",
      "funder_experience 0.013907895\n",
      "mac_wards 0.018651767\n",
      "gps_height_squared 0.010157934\n",
      "public_meeting 0.014457481\n",
      "num_private_over100 0.003974749\n",
      "second_best_wards 0.007880439\n",
      "wpt_name_kwa 0.010896024\n",
      "amount_tsh_not0_over1000 0.018854113\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X,y)\n",
    "\n",
    "for feat, imp in zip(new_features, pipe.feature_importances_):\n",
    "    print(feat, imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test_labels, df, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['all_functional'] = ((train.status_group == 'functional') | (train.status_group == 'functional needs repair'))\n",
    "train['all_needs_repair'] = ((train.status_group == 'non functional') | (train.status_group == 'functional needs repair'))\n",
    "\n",
    "pipe = ensemble.RandomForestClassifier(500, min_samples_leaf=5)\n",
    "\n",
    "\n",
    "X_test = test[new_features]\n",
    "\n",
    "X = train[new_features]\n",
    "y_func = train.all_functional\n",
    "y_nonfunc = train.all_needs_repair\n",
    "\n",
    "func_probs = pipe.fit(X, y_func).predict_proba(X_test)\n",
    "nonfunc_probs = pipe.fit(X, y_nonfunc).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = pd.DataFrame({'id': test.id, 'non functional': nonfunc_probs.T[1], 'functional': func_probs.T[1]})\n",
    "bayes['functional_needs_repair'] = bayes['non functional'] * bayes['functional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes['not_normal'] = bayes['non functional'] + bayes.functional + bayes.functional_needs_repair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['non functional', 'functional', 'functional_needs_repair']:\n",
    "    bayes[col] = bayes[col] / bayes.not_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes['guess_functional_needs_repair'] = (bayes.not_normal > bayes.not_normal.quantile(.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes['status_group'] = bayes.guess_functional_needs_repair.replace({True: 'functional_needs_repair'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes['nonfunc'] = ((bayes['non functional'] > bayes['functional']) & (bayes.status_group == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.nonfunc = bayes.nonfunc.replace({True: 'non functional'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>non functional</th>\n",
       "      <th>functional</th>\n",
       "      <th>functional_needs_repair</th>\n",
       "      <th>status_group</th>\n",
       "      <th>not_normal</th>\n",
       "      <th>guess_functional_needs_repair</th>\n",
       "      <th>nonfunc</th>\n",
       "      <th>fnl_functional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>0.382835</td>\n",
       "      <td>0.405285</td>\n",
       "      <td>0.211880</td>\n",
       "      <td>False</td>\n",
       "      <td>1.365582</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>0.219636</td>\n",
       "      <td>0.583643</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>False</td>\n",
       "      <td>1.534612</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>0.222971</td>\n",
       "      <td>0.594983</td>\n",
       "      <td>0.182046</td>\n",
       "      <td>False</td>\n",
       "      <td>1.372231</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>0.993885</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>False</td>\n",
       "      <td>1.003390</td>\n",
       "      <td>False</td>\n",
       "      <td>non functional</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>0.024236</td>\n",
       "      <td>0.951891</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>False</td>\n",
       "      <td>1.034832</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  non functional  functional  functional_needs_repair status_group  \\\n",
       "0  50785        0.382835    0.405285                 0.211880        False   \n",
       "1  51630        0.219636    0.583643                 0.196721        False   \n",
       "2  17168        0.222971    0.594983                 0.182046        False   \n",
       "3  45559        0.993885    0.003062                 0.003053        False   \n",
       "4  49871        0.024236    0.951891                 0.023873        False   \n",
       "\n",
       "   not_normal  guess_functional_needs_repair         nonfunc  fnl_functional  \n",
       "0    1.365582                          False           False            True  \n",
       "1    1.534612                          False           False            True  \n",
       "2    1.372231                          False           False            True  \n",
       "3    1.003390                          False  non functional           False  \n",
       "4    1.034832                          False           False            True  "
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes['fnl_functional'] = ((bayes.status_group == False) & (bayes.nonfunc == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.fnl_functional = bayes.fnl_functional.replace({True: 'functional'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14358, 9)"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.to_csv('waterpipe_bayes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wpt_name_school'] =((df.wpt_name.str.contains('shul')) | (df.wpt_name.str.contains('school')))\n",
    "df['wpt_name_kwa'] =((df.wpt_name.str.contains('kwa')))\n",
    "df['wpt_name_church'] = ((df.wpt_name.str.contains('msikitini')) | (df.wpt_name.str.contains('kanisani')) | (df.wpt_name.str.contains('kwa')))\n",
    "df['wpt_name_charles'] = (df.wpt_name.str.contains('msikitini'))\n",
    "df['wpt_name_market'] = ((df.wpt_name.str.contains('soko')) | (df.wpt_name.str.contains('madukani')))\n",
    "df['wpt_name_hospital'] = ((df.wpt_name.str.contains('kituo')) | (df.wpt_name.str.contains('afya')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5906040268456376"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.wpt_name.str.contains('afya')].functional.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mac\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pipe = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx', tree_method='exact',\n",
    "                      num_class = 4, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 14, colsample_bytree=.35)\n",
    "\n",
    "X = train[new_features]\n",
    "y = train.status_group\n",
    "\n",
    "X_test = test[new_features]\n",
    "\n",
    "pd.DataFrame({'id': test.id, 'status_group': pipe.fit(X, y).predict(X_test)}).to_csv('waterpipes_pumpitup3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mac_waterpoint_name2(wpt_name):\n",
    "    \n",
    "    # wpt_names dog\n",
    "    \n",
    "    schools = ['school', 'shul']\n",
    "    \n",
    "    if wpt_name in schools:\n",
    "        return 'mac_school'\n",
    "    \n",
    "    offices = ['ofisi']\n",
    "    if wpt_name in offices:\n",
    "        return 'mac_offices'\n",
    "    \n",
    "    churches = ['msikitini', 'kanisani', 'kwa']\n",
    "    if wpt_name in churches:\n",
    "        return 'mac_churches'\n",
    "    \n",
    "    hospitals = ['kituo']\n",
    "    if wpt_name in churches:\n",
    "        return 'hospitals'\n",
    "    \n",
    "    return 'misc'\n",
    "\n",
    "df['mac_waterpoint_name2'] = df.wpt_name.apply(mac_waterpoint_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mac_waterpoint_name2'] = df.wpt_name.apply(mac_waterpoint_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "misc            72422\n",
       "mac_churches     1075\n",
       "mac_school        258\n",
       "mac_offices         3\n",
       "Name: mac_waterpoint_name2, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mac_waterpoint_name2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True       63319\n",
       "False       6320\n",
       "missing     4119\n",
       "Name: public_meeting, dtype: int64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.public_meeting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'functional'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-608-2275281d3a50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wpt_name_church'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'functional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot_table\u001b[1;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)\u001b[0m\n\u001b[0;32m   5298\u001b[0m                            \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5299\u001b[0m                            \u001b[0mmargins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmargins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5300\u001b[1;33m                            margins_name=margins_name)\n\u001b[0m\u001b[0;32m   5301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5302\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mto_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'functional'"
     ]
    }
   ],
   "source": [
    "train.pivot_table(index='wpt_name_church', values='functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.public_meeting = pd.factorize(df.public_meeting)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_wards'] = ((df.ward == 'igosi') | (df.ward == 'imalinyi') | (df.ward == 'siha kati'))\n",
    "df['second_best_wards'] = ((df.ward == 'mdandu') | (df.ward == 'nduruma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['second_best_wards'] = ((train.ward == 'mdandu') | (train.ward == 'nduruma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "igosi               307\n",
       "imalinyi            252\n",
       "siha kati           232\n",
       "mdandu              231\n",
       "nduruma             217\n",
       "kitunda             203\n",
       "mishamo             203\n",
       "msindo              201\n",
       "chalinze            196\n",
       "maji ya chai        190\n",
       "usuka               187\n",
       "ngarenanyuki        172\n",
       "chanika             171\n",
       "vikindu             162\n",
       "mtwango             153\n",
       "matola              145\n",
       "zinga/ikerege       141\n",
       "wanging'ombe        139\n",
       "maramba             139\n",
       "itete               137\n",
       "magomeni            135\n",
       "ifakara             134\n",
       "kikatiti            134\n",
       "olkokola            133\n",
       "maposeni            130\n",
       "igongolo            129\n",
       "mvomero             129\n",
       "mlangali            125\n",
       "nkoma               122\n",
       "nkungulu            121\n",
       "                   ... \n",
       "uwanja wa ndege       1\n",
       "burungura             1\n",
       "linda                 1\n",
       "thawi                 1\n",
       "mkumbi                1\n",
       "machinjioni           1\n",
       "ukata                 1\n",
       "korongoni             1\n",
       "themi                 1\n",
       "kirongo               1\n",
       "kihangimahuka         1\n",
       "uchindile             1\n",
       "mawenzi               1\n",
       "mlimani               1\n",
       "kinungu               1\n",
       "izia                  1\n",
       "ifinga                1\n",
       "chinugulu             1\n",
       "kapilula              1\n",
       "nsemulwa              1\n",
       "nyamtinga             1\n",
       "mitole                1\n",
       "igogo                 1\n",
       "rasbura               1\n",
       "ikweha                1\n",
       "sungwisi              1\n",
       "matarawe              1\n",
       "kitete                1\n",
       "mwanga kaskazini      1\n",
       "simbay                1\n",
       "Name: ward, Length: 2092, dtype: int64"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ward.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6157337367624811"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.num_private >= 3].functional.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['functional'] = (train.status_group == 'functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.543081\n",
       "non functional             0.384242\n",
       "functional needs repair    0.072677\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.status_group.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.num_private_over100].functional.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59400.000000\n",
       "mean         0.474141\n",
       "std         12.236230\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max       1776.000000\n",
       "Name: num_private, dtype: float64"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.num_private.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        1\n",
       "12        0\n",
       "13        0\n",
       "14        2\n",
       "15        0\n",
       "16        3\n",
       "17        4\n",
       "18        0\n",
       "19        0\n",
       "20        5\n",
       "21        0\n",
       "22        4\n",
       "23        0\n",
       "24        0\n",
       "25        6\n",
       "26        0\n",
       "27        0\n",
       "28        0\n",
       "29        7\n",
       "         ..\n",
       "59370     0\n",
       "59371     0\n",
       "59372     0\n",
       "59373     0\n",
       "59374     0\n",
       "59375     0\n",
       "59376     0\n",
       "59377     0\n",
       "59378    15\n",
       "59379     0\n",
       "59380     0\n",
       "59381    71\n",
       "59382    44\n",
       "59383     0\n",
       "59384     0\n",
       "59385     0\n",
       "59386     0\n",
       "59387     0\n",
       "59388     0\n",
       "59389     0\n",
       "59390     0\n",
       "59391     0\n",
       "59392     0\n",
       "59393     0\n",
       "59394    64\n",
       "59395    76\n",
       "59396     0\n",
       "59397    55\n",
       "59398     0\n",
       "59399     0\n",
       "Name: mac_wards, Length: 59400, dtype: int64"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.mac_wards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    73758.000000\n",
       "mean       181.300944\n",
       "std        472.383194\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%         25.000000\n",
       "75%        217.000000\n",
       "max      30500.000000\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.population.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18035, 237)"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.amount_tsh > 25].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amt_tsh_pop_relationship'] = StandardScaler().fit_transform(df[['amount_tsh', 'population']]).T[0] /StandardScaler().fit_transform(df[['amount_tsh', 'population']]).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15305674,  0.14543177, -0.38168624, ..., -0.38168624,\n",
       "       -0.12977041, -0.38380318])"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
